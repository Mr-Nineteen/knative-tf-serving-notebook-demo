{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get training data and upload them to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:05 --:--:--     0\r",
      "100   162  100   162    0     0     26      0  0:00:06  0:00:06 --:--:--    35\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:06 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:07 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:08 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:09 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:10 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:11 --:--:--     0\r",
      "100 4959k  100 4959k    0     0   419k      0  0:00:11  0:00:11 --:--:-- 1169k\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -O -L https://github.com/vpavlin/odh-tensorflow-jobs/raw/master/training/num-dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket ODH-TENSORFLOW-JOBS-DEMO created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'tx000000000000000000004-005c863b76-101a-default',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'transfer-encoding': 'chunked',\n",
       "   'x-amz-request-id': 'tx000000000000000000004-005c863b76-101a-default',\n",
       "   'content-type': 'application/xml',\n",
       "   'date': 'Mon, 11 Mar 2019 10:41:58 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'IsTruncated': False,\n",
       " 'Marker': '',\n",
       " 'Contents': [{'Key': '/input-data/num-dataset.tar.gz',\n",
       "   'LastModified': datetime.datetime(2019, 3, 11, 10, 41, 58, 11000, tzinfo=tzlocal()),\n",
       "   'ETag': '\"938fb559ed093232ca5e985d1f370bf9\"',\n",
       "   'Size': 5078688,\n",
       "   'StorageClass': 'STANDARD',\n",
       "   'Owner': {'DisplayName': 'Ceph demo user', 'ID': 'nano'}}],\n",
       " 'Name': 'ODH-TENSORFLOW-JOBS-DEMO',\n",
       " 'Prefix': '',\n",
       " 'MaxKeys': 1000,\n",
       " 'EncodingType': 'url'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_bucket=\"ODH-TENSORFLOW-JOBS-DEMO\"\n",
    "\n",
    "import boto3, os\n",
    "conn = boto3.client(service_name='s3',\n",
    "    endpoint_url=os.environ['S3_ENDPOINT_URL'])\n",
    "\n",
    "buckets = [ b['Name'] for b in conn.list_buckets()['Buckets']]\n",
    "if my_bucket not in buckets:\n",
    "    resp = conn.create_bucket(Bucket=my_bucket)\n",
    "    if resp['ResponseMetadata']['HTTPStatusCode'] != 200:\n",
    "        raise Exception(\"Could not create bucket:(\")\n",
    "        \n",
    "    print(\"Bucket %s created\" % my_bucket)\n",
    "else:\n",
    "    print(\"Bucket %s exists\" % my_bucket)\n",
    "    \n",
    "key = \"/input-data/num-dataset.tar.gz\"\n",
    "conn.upload_file(Bucket=my_bucket, Key=key, Filename=\"num-dataset.tar.gz\")\n",
    "conn.list_objects(Bucket=my_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'tx000000000000000000006-005c863b76-101a-default',\n",
       "  'HostId': '',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'transfer-encoding': 'chunked',\n",
       "   'x-amz-request-id': 'tx000000000000000000006-005c863b76-101a-default',\n",
       "   'content-type': 'application/xml',\n",
       "   'date': 'Mon, 11 Mar 2019 10:41:58 GMT'},\n",
       "  'RetryAttempts': 0},\n",
       " 'IsTruncated': False,\n",
       " 'Marker': '',\n",
       " 'Contents': [{'Key': '/input-data/num-dataset.tar.gz',\n",
       "   'LastModified': datetime.datetime(2019, 3, 11, 10, 41, 58, 11000, tzinfo=tzlocal()),\n",
       "   'ETag': '\"938fb559ed093232ca5e985d1f370bf9\"',\n",
       "   'Size': 5078688,\n",
       "   'StorageClass': 'STANDARD',\n",
       "   'Owner': {'DisplayName': 'Ceph demo user', 'ID': 'nano'}},\n",
       "  {'Key': '/output-model/model_out.tgz',\n",
       "   'LastModified': datetime.datetime(2019, 3, 11, 10, 41, 58, 137000, tzinfo=tzlocal()),\n",
       "   'ETag': '\"e747057d9f6d124dd12222a588cd8b43\"',\n",
       "   'Size': 1023846,\n",
       "   'StorageClass': 'STANDARD',\n",
       "   'Owner': {'DisplayName': 'Ceph demo user', 'ID': 'nano'}}],\n",
       " 'Name': 'ODH-TENSORFLOW-JOBS-DEMO',\n",
       " 'Prefix': '',\n",
       " 'MaxKeys': 1000,\n",
       " 'EncodingType': 'url'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = \"/output-model/model_out.tgz\"\n",
    "conn.upload_file(Bucket=my_bucket, Key=key, Filename=\"model_out.tgz\")\n",
    "conn.list_objects(Bucket=my_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.copy_object(Bucket=my_bucket, CopySource=\"TEST/output-model/model_out.tgz\", Key=\"/output-model/model_out.tgz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install OpenShift client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:05 --:--:--     0\r",
      "100   654    0   654    0     0    114      0 --:--:--  0:00:05 --:--:--   154\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:06 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:07 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:08 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:09 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:10 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:11 --:--:--     0\r",
      "100 53.8M  100 53.8M    0     0  4662k      0  0:00:11  0:00:11 --:--:-- 11.7M\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.xattr.security.selinux'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.xattr.security.selinux'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.xattr.security.selinux'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.xattr.security.selinux'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -o oc.tar.gz -L https://github.com/openshift/origin/releases/download/v3.11.0/openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit.tar.gz\n",
    "tar xzf oc.tar.gz\n",
    "cp openshift-origin-client-tools-v3.11.0-0cbc58b-linux-64bit/oc ~/../bin/oc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Service Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system:serviceaccount:tf-demo:jupyter-tensorflow\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc whoami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List templates\n",
    "\n",
    "You should see templates imported from [odh-tensorflow-jobs](https://github.com/vpavlin/odh-tensorflow-jobs/tree/master/openshift) repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                    DESCRIPTION                                                                        PARAMETERS    OBJECTS\n",
      "jupyter-notebook-workspace-tensorflow   Template for deploying Tensorflow enable Jupyter Notebook images with persist...   4 (all set)   7\n",
      "odh-config                              Template to configure basic components of ODH ML flow                              3 (3 blank)   1\n",
      "odh-tensorflow-serving                  Template to serve models using tensorflow                                          5 (all set)   2\n",
      "odh-tensorflow-serving-knative          Template to serve models using tensorflow and knative                              7 (all set)   1\n",
      "odh-tensorflow-training                 Template to train models using tensorflow                                          9 (all set)   1\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc get templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List parameters for Tensorflow serving template\n",
    "\n",
    "Once the training job is completed, we can deploy the serving endpoint - see the parametrs below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   DESCRIPTION                                                                     GENERATOR           VALUE\n",
      "APP_NAME               Short name of your application (to be used in OpenShift artifact names)                             demo\n",
      "INPUT_MODEL_LOCATION   Location where the resulting model will be stored                                                   s3://MY-BUCKET/model-out/\n",
      "MODEL_NAME             Name of the model                                                                                   mnist\n",
      "MEMORY                 Memory limit to be assigned to the job                                                              1Gi\n",
      "CPU                    Limit for number of cores to assign to the job                                                      1\n",
      "SCALE_FACTOR           Number of requests served by a single instance/pod                                                  1\n",
      "NAMESPACE              Namespace name the service is supposed to run in (probably current namespace)                       myproject\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc process odh-tensorflow-serving-knative --parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Tensorflow serving endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service.serving.knative.dev/ohd-tensorflow-serving-knative-from-jupyter created\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc process odh-tensorflow-serving-knative \\\n",
    "    -p APP_NAME=from-jupyter \\\n",
    "    -p INPUT_MODEL_LOCATION=\"s3://ODH-TENSORFLOW-JOBS-DEMO/output-model\" \\\n",
    "    -p MODEL_NAME=\"intect\" \\\n",
    "    -p NAMESPACE=tf-demo \\\n",
    "        | oc apply -f -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                          DOMAIN                                                            LATESTCREATED                                       LATESTREADY                                         READY     REASON\n",
      "ohd-tensorflow-serving-knative-from-jupyter   ohd-tensorflow-serving-knative-from-jupyter.tf-demo.example.com   ohd-tensorflow-serving-knative-from-jupyter-00001   ohd-tensorflow-serving-knative-from-jupyter-00001   True      \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc get kservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY     STATUS      RESTARTS   AGE\n",
      "ceph-nano-0                                                       1/1       Running     0          84m\n",
      "jupyter-tensorflow-1-744ww                                        2/2       Running     0          87m\n",
      "jupyter-tensorflow-1-deploy                                       0/1       Completed   0          87m\n",
      "odh-tensorflow-serving-1-build                                    0/1       Completed   0          88m\n",
      "odh-tensorflow-training-1-build                                   0/1       Completed   0          88m\n",
      "ohd-tensorflow-serving-knative-from-jupyter-00001-deployme7z2cb   2/2       Running     0          33s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "oc get pods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling prediction endpoint\n",
    "\n",
    "We need to configure the server name - you can see the name of the deployed service above as `service/odh-tensorflow-serving-from-jupyter` - we'll use the part after slash. The model name needs to match the name defined in `MODEL_NAME` parameter above.\n",
    "\n",
    "You can use [2.png](https://github.com/vpavlin/odh-tensorflow-jobs/blob/master/2.png) to test the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:05 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:05 --:--:--     0\r",
      "100   140  100   140    0     0     23      0  0:00:06  0:00:05  0:00:01    40\n",
      "\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:07 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:08 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:09 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:10 --:--:--     0\r",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:11 --:--:--     0\r",
      "100  1867  100  1867    0     0    161      0  0:00:11  0:00:11 --:--:--   457\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -O -L https://github.com/vpavlin/odh-tensorflow-jobs/raw/master/2.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloaded image \n",
    "\n",
    "![2.png](2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_file: str):\n",
    "    \"\"\"Pre-process the input to match the input expected by the serving.\n",
    "    \":returns: ndarray, preprocessed image\n",
    "    \"\"\"\n",
    "    image = misc.imread(image_file, mode='L')\n",
    "    # resize the image to desired format\n",
    "    image = misc.imresize(image, size=[32, 32])\n",
    "    # normalize the image\n",
    "    image = image.astype(dtype=np.float32) / 255\n",
    "    # expand the dimension\n",
    "    image = np.expand_dims(image, axis=-1)\n",
    "\n",
    "    return image.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib/python3.6/site-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/opt/app-root/lib/python3.6/site-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n"
     ]
    }
   ],
   "source": [
    "# Wrap bitstring in JSON\n",
    "instance = []\n",
    "for i in [\"2.png\", \"4.png\", \"1.png\", \"9.png\"]:\n",
    "    instance.append(preprocess_image(i))\n",
    "    \n",
    "data = json.dumps({\"signature_name\": \"prediction\", \"instances\": instance})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%bash --out KSERVICE_DOMAIN\n",
    "\n",
    "oc get kservice ohd-tensorflow-serving-knative-from-jupyter -o jsonpath='{.status.domain}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "INGRESS_GATEWAY=\"aaa5c9f9743e711e9aa7f0a0bd8df71a-418337139.us-east-1.elb.amazonaws.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\\n    \"predictions\": [[\"2\"], [\"4\"], [\"1\"], [\"9\"]\\n    ]\\n}'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_response = requests.post(\"http://%s/v1/models/intect:predict\" % INGRESS_GATEWAY, data=data, headers={\"host\": KSERVICE_DOMAIN, \"content-type\":\"application/json\"})\n",
    "json_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
